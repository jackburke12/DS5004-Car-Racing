# configs/td3.yaml
agent_name: td3

env:
  id: CarRacing-v3
  render_mode: null

  # Speed optimization:
  # Reduce frame stack from 4 -> 3 (large CNN speed gain)
  num_stack: 3

training:
  # TD3 typically converges by ~400â€“600 episodes.
  episodes: 600
  max_steps_per_episode: 800       # Lowering this reduces env runtime ~20%

  warmup_steps: 3000               # TD3 learns faster, needs less warmup
  train_every: 2                   # Update every 2 env steps instead of every step
  updates_per_step: 1

  # Hard updates still done by train.py every N steps
  target_update_every: 1000

  # TD3-only: delayed policy update (big speed boost)
  policy_freq: 3

hyperparameters:
  gamma: 0.99

  # TD3 traditionally uses lower learning rates (1e-3 can destabilize critics)
  lr: 0.0003

  # Speed optimization: larger batch size
  batch_size: 128

  # Reduce memory + increase training speed
  replay_size: 30000

exploration:
  # Unused for TD3, but kept for BaseAgent compatibility
  eps_start: 1.0
  eps_end: 0.05
  eps_decay_steps: 500000

output:
  checkpoint_dir: checkpoints/td3
  results_csv: results/td3_results.csv
